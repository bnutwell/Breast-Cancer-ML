{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI+ 1-step Prediction Pipeline\n",
    "\n",
    "This notebook will accept a folder of new ultrasound images and labels\n",
    "    and return a dataframe of results and a dataframe of MAP scores\n",
    "\n",
    "To use this notebook:\n",
    "\n",
    "0.  Install relevant packages including ultralytics, tqdm, mapcalc\n",
    "1.  Prepare images by cropping border artifacts/text, leaving only the full ultrasound image\n",
    "    : See the notebook \\data_preprocessing\\image_cropping_AIplus.ipynb for example of how to do this\n",
    "2.  Place images in the local subdirectory \\Data\\ \n",
    "    following the pattern \\Data\\Test_images\\imgs and \\Data\\Test_images\\jsons\n",
    "3.  Place trained model in the \\Trained_Models\\ subdirectory\n",
    "4.  Update the model and data paths in the cell below this one\n",
    "5.  Run the notebook cells in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "this_path = os.getcwd()\n",
    "data_basepath = this_path + '\\\\Data\\\\External_test_cropped\\\\'\n",
    "model_basepath = this_path + '\\\\Trained_Models\\\\'\n",
    "\n",
    "# Update this with path to trained YOLOv8 1-step model\n",
    "MODEL_PATH = model_basepath + 'best_yolo_1step.pt'\n",
    "\n",
    "# Update this with path to images and labels to be evaluated\n",
    "TEST_SET_PATH = data_basepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.142  Python-3.10.2 torch-2.0.1+cpu CPU (11th Gen Intel Core(TM) i7-1185G7 3.00GHz)\n",
      "Setup complete  (8 CPUs, 15.7 GB RAM, 409.3/952.6 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import ultralytics\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from mapcalc import calculate_map, calculate_map_range\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to draw images with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image_path, boxes, labels, scores, ground_truth_boxes, ground_truth_labels, output_path, normalized_bbox=True):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Get the image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Iterate over the boxes\n",
    "    for (box, label, score) in zip(boxes, labels, scores):\n",
    "        # Convert normalized coordinates to pixel coordinates\n",
    "        x1, y1, x2, y2 = tuple(box)\n",
    "        if normalized_bbox:\n",
    "            x1, y1, x2, y2 = int(x1 * width), int(y1 * height), int(x2 * width), int(y2 * height)\n",
    "        else:\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "        # Draw the box\n",
    "\n",
    "        # Multi-class\n",
    "        if label == 0:\n",
    "            tumor = \"benign\"\n",
    "            color = (0, 255, 0)\n",
    "        elif label == 1:\n",
    "            tumor = \"malignant\"\n",
    "            color = (0, 0, 255)\n",
    "        \n",
    "        # # Single-class\n",
    "        # if label == 0:\n",
    "        #     tumor = \"tumor\"\n",
    "        #     color = (255, 0, 0)\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        # Prepare the label and confidence\n",
    "        text = f\"{tumor}: {score:.2f}\"\n",
    "\n",
    "        # Draw the label and confidence\n",
    "        cv2.putText(image, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2, cv2.LINE_AA)\n",
    "\n",
    "    for (box, label) in zip(ground_truth_boxes, ground_truth_labels):\n",
    "        # Convert normalized coordinates to pixel coordinates\n",
    "        x1, y1, x2, y2 = tuple(box)\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "        # Draw the box\n",
    "\n",
    "        if label == 0:\n",
    "            tumor = \"I-benign\"\n",
    "            color = (0, 255, 0)\n",
    "        elif label == 1:\n",
    "            tumor = \"I-malignant\"\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        # Draw the label and confidence\n",
    "        cv2.putText(image, tumor, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2, cv2.LINE_AA)\n",
    "\n",
    "        print(image_path)\n",
    "        print(label)\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
    "\n",
    "    # Save the image\n",
    "    cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Test Images: 4\n"
     ]
    }
   ],
   "source": [
    "# set relevant paths\n",
    "imgs_dir = os.path.join(TEST_SET_PATH, \"imgs\")\n",
    "output_dir = os.path.join(TEST_SET_PATH, \"outputs\")\n",
    "jsons_dir= os.path.join(TEST_SET_PATH, \"jsons\")\n",
    "img_list = glob(os.path.join(imgs_dir, \"*.jpg\"))\n",
    "\n",
    "print(f\"Total Number of Test Images: {len(img_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Trained Model\n",
    "model = YOLO(MODEL_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\GTMS Projects\\Practicum\\AIplus-Practicum-Final\\Data\\External_test_cropped\\imgs\\0AD131A0D42742098EE0ADD670C4C5C2_2737480.jpg: 448x640 1 malignant, 1770.2ms\n",
      "Speed: 2.0ms preprocess, 1770.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      " 25%|██▌       | 1/4 [00:03<00:11,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\GTMS Projects\\Practicum\\AIplus-Practicum-Final\\Data\\External_test_cropped\\imgs\\0AD131A0D42742098EE0ADD670C4C5C2_2737480.jpg\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\GTMS Projects\\Practicum\\AIplus-Practicum-Final\\Data\\External_test_cropped\\imgs\\0AD131A0D42742098EE0ADD670C4C5C2_2737481.jpg: 480x640 1 malignant, 1922.0ms\n",
      "Speed: 2.0ms preprocess, 1922.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      " 50%|█████     | 2/4 [00:05<00:05,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\GTMS Projects\\Practicum\\AIplus-Practicum-Final\\Data\\External_test_cropped\\imgs\\0AD131A0D42742098EE0ADD670C4C5C2_2737481.jpg\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\GTMS Projects\\Practicum\\AIplus-Practicum-Final\\Data\\External_test_cropped\\imgs\\0AD131A0D42742098EE0ADD670C4C5C2_2737487.jpg: 576x640 2 malignants, 2264.3ms\n",
      "Speed: 3.1ms preprocess, 2264.3ms inference, 1.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      " 75%|███████▌  | 3/4 [00:08<00:02,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\GTMS Projects\\Practicum\\AIplus-Practicum-Final\\Data\\External_test_cropped\\imgs\\0AD131A0D42742098EE0ADD670C4C5C2_2737487.jpg\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\GTMS Projects\\Practicum\\AIplus-Practicum-Final\\Data\\External_test_cropped\\imgs\\0AD131A0D42742098EE0ADD670C4C5C2_2737488.jpg: 576x640 1 malignant, 2378.5ms\n",
      "Speed: 4.0ms preprocess, 2378.5ms inference, 0.0ms postprocess per image at shape (1, 3, 576, 640)\n",
      "100%|██████████| 4/4 [00:10<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\GTMS Projects\\Practicum\\AIplus-Practicum-Final\\Data\\External_test_cropped\\imgs\\0AD131A0D42742098EE0ADD670C4C5C2_2737488.jpg\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "map_dict = {\"img_name\":[], \"mAP50\":[], \"mAP50-95\":[]}\n",
    "\n",
    "for img in tqdm(img_list):\n",
    "\n",
    "    result = model.predict(img, imgsz=640, conf=0.5, iou=0.7, augment=True)\n",
    "    # result = model.predict(img, imgsz=640, conf=0.25, iou=0.7, augment=True)\n",
    "\n",
    "    img_name = os.path.basename(img)\n",
    "    output_path = os.path.join(output_dir, img_name)\n",
    "    json_file = os.path.join(jsons_dir, img_name.replace(\".jpg\", \".json\"))\n",
    "\n",
    "    with open(json_file, \"r\") as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "    ground_truth = {\"boxes\":[], \"labels\":[]}\n",
    "    result_dict = {\"boxes\":[], \"labels\":[], \"scores\":[]}\n",
    "\n",
    "    for shape in test_data[\"shapes\"]:\n",
    "        # if shape['label'] != \"border\":\n",
    "        #     ground_truth[\"labels\"].append(shape[\"label\"])\n",
    "        #     ground_truth[\"boxes\"].append([shape[\"points\"][0][0], shape[\"points\"][0][1], shape[\"points\"][1][0], shape[\"points\"][1][1]])   \n",
    "\n",
    "        # Multi-class\n",
    "        if shape['label'] == \"benign\":\n",
    "            shape['label'] = 0\n",
    "            ground_truth[\"labels\"].append(shape[\"label\"])\n",
    "            ground_truth[\"boxes\"].append([shape[\"points\"][0][0], shape[\"points\"][0][1], shape[\"points\"][1][0], shape[\"points\"][1][1]])            \n",
    "        elif shape['label'] == \"malignant\":\n",
    "            shape['label'] = 1\n",
    "            ground_truth[\"labels\"].append(shape[\"label\"])\n",
    "            ground_truth[\"boxes\"].append([shape[\"points\"][0][0], shape[\"points\"][0][1], shape[\"points\"][1][0], shape[\"points\"][1][1]])\n",
    "        \n",
    "        # if shape['label'] != 'border':\n",
    "        #     shape['label'] = 0\n",
    "        #     ground_truth[\"labels\"].append(shape[\"label\"])\n",
    "        #     ground_truth[\"boxes\"].append([shape[\"points\"][0][0], shape[\"points\"][0][1], shape[\"points\"][1][0], shape[\"points\"][1][1]])\n",
    "\n",
    "    cls_list = []\n",
    "    conf_list = []\n",
    "    nboxes_list = []\n",
    "    boxes_list = []\n",
    "\n",
    "    for i in range(len(result[0].boxes.cls.cpu().detach().numpy())):\n",
    "        cls_list.append(int(result[0].boxes.cls.cpu().detach().numpy()[i].tolist()))\n",
    "        conf_list.append(result[0].boxes.conf.cpu().detach().numpy()[i].tolist())\n",
    "        nboxes_list.append(result[0].boxes.xyxyn.cpu().detach().numpy()[i].tolist())\n",
    "        boxes_list.append(result[0].boxes.xyxy.cpu().detach().numpy()[i].tolist())\n",
    "\n",
    "        result_dict[\"labels\"].append(int(result[0].boxes.cls.cpu().detach().numpy()[i].tolist()))\n",
    "        result_dict[\"boxes\"].append(result[0].boxes.xyxy.cpu().detach().numpy()[i].tolist())\n",
    "        result_dict[\"scores\"].append(result[0].boxes.conf.cpu().detach().numpy()[i].tolist())\n",
    "    \n",
    "    draw_boxes(img, nboxes_list, cls_list, conf_list, ground_truth['boxes'], ground_truth['labels'], output_path)\n",
    "\n",
    "    # print(ground_truth)\n",
    "    # print(result_dict)\n",
    "\n",
    "    map50 = calculate_map(ground_truth, result_dict, 0.5)\n",
    "    map5095 = calculate_map_range(ground_truth, result_dict, 0.5, 0.95, 0.05)\n",
    "\n",
    "    map_dict[\"img_name\"].append(img_name)\n",
    "    map_dict[\"mAP50\"].append(map50)\n",
    "    map_dict[\"mAP50-95\"].append(map5095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       img_name  mAP50  mAP50-95\n",
      "0  0AD131A0D42742098EE0ADD670C4C5C2_2737480.jpg    1.0       0.1\n",
      "1  0AD131A0D42742098EE0ADD670C4C5C2_2737481.jpg    1.0       0.6\n",
      "2  0AD131A0D42742098EE0ADD670C4C5C2_2737487.jpg    1.0       0.4\n",
      "3  0AD131A0D42742098EE0ADD670C4C5C2_2737488.jpg    1.0       0.5\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(map_dict)\n",
    "print(df.iloc[0:5,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP50 score: 1.0\n",
      "mAP50-95 score: 0.4\n",
      "# of images not detected correctly: 0\n"
     ]
    }
   ],
   "source": [
    "# mAP50\n",
    "print('mAP50 score:',round(df['mAP50'].mean(),3))\n",
    "print('mAP50-95 score:',round(df['mAP50-95'].mean(),3))\n",
    "# Images Not detected Correctly\n",
    "print('# of images not detected correctly:',len(df[df['mAP50']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save mAP results to csv file\n",
    "df.to_csv(os.path.join(TEST_SET_PATH, \"mAP_results.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
